{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yno3fm36xqnnc8/logistic-regression-the-jax-way?scriptVersionId=139344285\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"3235ddf2","metadata":{"papermill":{"duration":0.006535,"end_time":"2023-08-08T22:51:06.962333","exception":false,"start_time":"2023-08-08T22:51:06.955798","status":"completed"},"tags":[]},"source":["## Logistic Regression the JAX Way"]},{"cell_type":"code","execution_count":1,"id":"b65a9fe3","metadata":{"execution":{"iopub.execute_input":"2023-08-08T22:51:06.976888Z","iopub.status.busy":"2023-08-08T22:51:06.976492Z","iopub.status.idle":"2023-08-08T22:51:08.314146Z","shell.execute_reply":"2023-08-08T22:51:08.312922Z"},"papermill":{"duration":1.348838,"end_time":"2023-08-08T22:51:08.316809","exception":false,"start_time":"2023-08-08T22:51:06.967971","status":"completed"},"tags":[]},"outputs":[],"source":["import pandas as pd\n","import jax\n","import jax.numpy as jnp\n","from collections import namedtuple"]},{"cell_type":"markdown","id":"fbfd7630","metadata":{"papermill":{"duration":0.005244,"end_time":"2023-08-08T22:51:08.327681","exception":false,"start_time":"2023-08-08T22:51:08.322437","status":"completed"},"tags":[]},"source":["The goal of this notebook is to demonstrate how to do logistic regression with the JAX library. I'm sure there are other, better ways to do this, but this is a good start. For this example, let's use the Titanic dataset found on Kaggle. "]},{"cell_type":"code","execution_count":2,"id":"7d7c272b","metadata":{"execution":{"iopub.execute_input":"2023-08-08T22:51:08.340352Z","iopub.status.busy":"2023-08-08T22:51:08.339725Z","iopub.status.idle":"2023-08-08T22:51:08.849938Z","shell.execute_reply":"2023-08-08T22:51:08.848656Z"},"papermill":{"duration":0.519543,"end_time":"2023-08-08T22:51:08.852756","exception":false,"start_time":"2023-08-08T22:51:08.333213","status":"completed"},"tags":[]},"outputs":[],"source":["test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n","train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n","\n","pclasses = train_data['Pclass']\n","pclasses = jnp.array(pclasses).reshape((-1, 1))\n","\n","survived = train_data['Survived']\n","survived = jnp.array(survived).reshape((-1, 1))"]},{"cell_type":"markdown","id":"4ba4186e","metadata":{"papermill":{"duration":0.005239,"end_time":"2023-08-08T22:51:08.863703","exception":false,"start_time":"2023-08-08T22:51:08.858464","status":"completed"},"tags":[]},"source":["Our logistic regression model requires two parameters, the weight $w$ and the bias $b$. We will regress over a single feature: passenger class number."]},{"cell_type":"code","execution_count":3,"id":"4143957c","metadata":{"execution":{"iopub.execute_input":"2023-08-08T22:51:08.876065Z","iopub.status.busy":"2023-08-08T22:51:08.87566Z","iopub.status.idle":"2023-08-08T22:51:08.935268Z","shell.execute_reply":"2023-08-08T22:51:08.933946Z"},"papermill":{"duration":0.068966,"end_time":"2023-08-08T22:51:08.937965","exception":false,"start_time":"2023-08-08T22:51:08.868999","status":"completed"},"tags":[]},"outputs":[],"source":["LogisticRegressionParams = namedtuple('LogisticRegressionParams', 'w b')\n","model_params = LogisticRegressionParams(jnp.zeros([1, 2]), jnp.zeros([2]))"]},{"cell_type":"markdown","id":"1af13a64","metadata":{"papermill":{"duration":0.005455,"end_time":"2023-08-08T22:51:08.950507","exception":false,"start_time":"2023-08-08T22:51:08.945052","status":"completed"},"tags":[]},"source":["First we define the `predict` function. It takes the model parameters `params` and some regressors `x`, and uses them to create a single prediction. The model implemented here uses the `softmax` function to determine a probability distribution over the two possible states, $0$ (dead) and $1$ (living). Specifically, the value $${z} = {w}{x} + {b}$$ is computed. In our case, this leaves us with a two-dimensional vector which is fed to the softmax function, mapping $(u,v)$ to $(\\frac{\\exp{u}}{\\exp{u} +\\exp{v}}, \\frac{\\exp{v}}{\\exp{u} +\\exp{v}})$.\n","\n","Observe the `@jax.jit` decorator. This tells JAX to just-in-time compile our prediction function. Not all functions can be jitted, see [this](https://jax.readthedocs.io/en/latest/jax-101/02-jitting.html#why-can-t-we-just-jit-everything) for more."]},{"cell_type":"code","execution_count":4,"id":"b7d8b372","metadata":{"execution":{"iopub.execute_input":"2023-08-08T22:51:08.962904Z","iopub.status.busy":"2023-08-08T22:51:08.962492Z","iopub.status.idle":"2023-08-08T22:51:08.968763Z","shell.execute_reply":"2023-08-08T22:51:08.967782Z"},"papermill":{"duration":0.015067,"end_time":"2023-08-08T22:51:08.970849","exception":false,"start_time":"2023-08-08T22:51:08.955782","status":"completed"},"tags":[]},"outputs":[],"source":["@jax.jit\n","def predict(params: LogisticRegressionParams, x: jnp.array):\n","    z = params.w.transpose() @ x + params.b\n","    return jax.nn.softmax(z)"]},{"cell_type":"markdown","id":"0592b777","metadata":{"papermill":{"duration":0.006148,"end_time":"2023-08-08T22:51:08.982474","exception":false,"start_time":"2023-08-08T22:51:08.976326","status":"completed"},"tags":[]},"source":["The `vpredict` function shows how we can vectorize functions with JAX, allowing us to compute predictions in batches."]},{"cell_type":"code","execution_count":5,"id":"09b54562","metadata":{"execution":{"iopub.execute_input":"2023-08-08T22:51:08.995388Z","iopub.status.busy":"2023-08-08T22:51:08.994576Z","iopub.status.idle":"2023-08-08T22:51:08.999714Z","shell.execute_reply":"2023-08-08T22:51:08.998921Z"},"papermill":{"duration":0.013959,"end_time":"2023-08-08T22:51:09.001803","exception":false,"start_time":"2023-08-08T22:51:08.987844","status":"completed"},"tags":[]},"outputs":[],"source":["@jax.jit\n","def vpredict(params, regressors):\n","    f = jax.vmap(lambda x: predict(params, x))\n","    return f(regressors)"]},{"cell_type":"markdown","id":"fb122d95","metadata":{"papermill":{"duration":0.005033,"end_time":"2023-08-08T22:51:09.012267","exception":false,"start_time":"2023-08-08T22:51:09.007234","status":"completed"},"tags":[]},"source":["The `nll` function computes the negative log-likelihood of the data as a function of `params`. That is, it computes the probability of the observed data given the model. The `take_along_axis` function is used to index the predictions, retrieving the probability of the particular occurence. Finally the mean is taken across the whole batch."]},{"cell_type":"code","execution_count":6,"id":"9c8dae74","metadata":{"execution":{"iopub.execute_input":"2023-08-08T22:51:09.024698Z","iopub.status.busy":"2023-08-08T22:51:09.024108Z","iopub.status.idle":"2023-08-08T22:51:09.029366Z","shell.execute_reply":"2023-08-08T22:51:09.028582Z"},"papermill":{"duration":0.013865,"end_time":"2023-08-08T22:51:09.031332","exception":false,"start_time":"2023-08-08T22:51:09.017467","status":"completed"},"tags":[]},"outputs":[],"source":["@jax.jit\n","def nll(params: LogisticRegressionParams, regressors: jnp.array, labels: jnp.array):\n","    probs = vpredict(params, regressors)\n","    log_probs = jnp.log(probs)\n","    return -jnp.take_along_axis(log_probs, labels, 1).mean()"]},{"cell_type":"markdown","id":"3df3b9fe","metadata":{"papermill":{"duration":0.005173,"end_time":"2023-08-08T22:51:09.041926","exception":false,"start_time":"2023-08-08T22:51:09.036753","status":"completed"},"tags":[]},"source":["Now it's time to train the model. This is accomplished by gradient descent. The gradient of the negative log-likelihood function `nll` is determined using `jax.grad`. The gradient over the entire training set is computed and the model parameters are updated according to the rule\n","$$\n","p \\leftarrow p - \\eta \\nabla{\\ell},\n","$$\n","where $\\eta$ is the learning rate (set here to $0.01$)."]},{"cell_type":"code","execution_count":7,"id":"98618aa3","metadata":{"execution":{"iopub.execute_input":"2023-08-08T22:51:09.05434Z","iopub.status.busy":"2023-08-08T22:51:09.053814Z","iopub.status.idle":"2023-08-08T22:51:12.469514Z","shell.execute_reply":"2023-08-08T22:51:12.468162Z"},"papermill":{"duration":3.425224,"end_time":"2023-08-08T22:51:12.472342","exception":false,"start_time":"2023-08-08T22:51:09.047118","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["0.6931472\n","0.6381312\n","0.6353234\n","0.63285196\n","0.6306094\n","0.6285747\n","0.62672895\n","0.6250547\n","0.6235363\n","0.62215906\n"]}],"source":["learning_rate = 1e-2\n","loss_grad_fn = jax.grad(nll)\n","for i in range(1_000):\n","    if i % 100 == 0:\n","        print(nll(model_params, pclasses, survived))\n","    grads = loss_grad_fn(model_params, pclasses, survived)\n","    model_params = LogisticRegressionParams(model_params.w - learning_rate * grads[0], model_params.b - learning_rate * grads[1])"]},{"cell_type":"markdown","id":"aa425b0a","metadata":{"papermill":{"duration":0.006049,"end_time":"2023-08-08T22:51:12.484943","exception":false,"start_time":"2023-08-08T22:51:12.478894","status":"completed"},"tags":[]},"source":["Now that the model is trained, let's see how well it performs."]},{"cell_type":"code","execution_count":8,"id":"201faca3","metadata":{"execution":{"iopub.execute_input":"2023-08-08T22:51:12.499023Z","iopub.status.busy":"2023-08-08T22:51:12.498628Z","iopub.status.idle":"2023-08-08T22:51:12.686373Z","shell.execute_reply":"2023-08-08T22:51:12.685088Z"},"papermill":{"duration":0.197606,"end_time":"2023-08-08T22:51:12.688751","exception":false,"start_time":"2023-08-08T22:51:12.491145","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["accuracy is 67.90%\n"]}],"source":["preds = vpredict(model_params, pclasses).argmax(axis=1).reshape((-1, 1))\n","accuracy = 1.0 - abs(preds-survived).mean()\n","print(f\"accuracy is {100.0*accuracy:.2f}%\")"]},{"cell_type":"markdown","id":"6f4064fe","metadata":{"papermill":{"duration":0.005857,"end_time":"2023-08-08T22:51:12.701119","exception":false,"start_time":"2023-08-08T22:51:12.695262","status":"completed"},"tags":[]},"source":["Finally, we generate predictions and save it to `/kaggle/working/submission.csv`."]},{"cell_type":"code","execution_count":9,"id":"66838cce","metadata":{"execution":{"iopub.execute_input":"2023-08-08T22:51:12.715282Z","iopub.status.busy":"2023-08-08T22:51:12.714251Z","iopub.status.idle":"2023-08-08T22:51:12.858804Z","shell.execute_reply":"2023-08-08T22:51:12.857705Z"},"papermill":{"duration":0.154125,"end_time":"2023-08-08T22:51:12.861171","exception":false,"start_time":"2023-08-08T22:51:12.707046","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","      <th>Survived</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>892</td>\n","      <td>3</td>\n","      <td>Kelly, Mr. James</td>\n","      <td>male</td>\n","      <td>34.5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>330911</td>\n","      <td>7.8292</td>\n","      <td>NaN</td>\n","      <td>Q</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>893</td>\n","      <td>3</td>\n","      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n","      <td>female</td>\n","      <td>47.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>363272</td>\n","      <td>7.0000</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>894</td>\n","      <td>2</td>\n","      <td>Myles, Mr. Thomas Francis</td>\n","      <td>male</td>\n","      <td>62.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>240276</td>\n","      <td>9.6875</td>\n","      <td>NaN</td>\n","      <td>Q</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>895</td>\n","      <td>3</td>\n","      <td>Wirz, Mr. Albert</td>\n","      <td>male</td>\n","      <td>27.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>315154</td>\n","      <td>8.6625</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>896</td>\n","      <td>3</td>\n","      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n","      <td>female</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3101298</td>\n","      <td>12.2875</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>413</th>\n","      <td>1305</td>\n","      <td>3</td>\n","      <td>Spector, Mr. Woolf</td>\n","      <td>male</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>A.5. 3236</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>414</th>\n","      <td>1306</td>\n","      <td>1</td>\n","      <td>Oliva y Ocana, Dona. Fermina</td>\n","      <td>female</td>\n","      <td>39.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>PC 17758</td>\n","      <td>108.9000</td>\n","      <td>C105</td>\n","      <td>C</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>415</th>\n","      <td>1307</td>\n","      <td>3</td>\n","      <td>Saether, Mr. Simon Sivertsen</td>\n","      <td>male</td>\n","      <td>38.5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>SOTON/O.Q. 3101262</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>416</th>\n","      <td>1308</td>\n","      <td>3</td>\n","      <td>Ware, Mr. Frederick</td>\n","      <td>male</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>359309</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>417</th>\n","      <td>1309</td>\n","      <td>3</td>\n","      <td>Peter, Master. Michael J</td>\n","      <td>male</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2668</td>\n","      <td>22.3583</td>\n","      <td>NaN</td>\n","      <td>C</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>418 rows Ã— 12 columns</p>\n","</div>"],"text/plain":["     PassengerId  Pclass                                          Name  \\\n","0            892       3                              Kelly, Mr. James   \n","1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n","2            894       2                     Myles, Mr. Thomas Francis   \n","3            895       3                              Wirz, Mr. Albert   \n","4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n","..           ...     ...                                           ...   \n","413         1305       3                            Spector, Mr. Woolf   \n","414         1306       1                  Oliva y Ocana, Dona. Fermina   \n","415         1307       3                  Saether, Mr. Simon Sivertsen   \n","416         1308       3                           Ware, Mr. Frederick   \n","417         1309       3                      Peter, Master. Michael J   \n","\n","        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \\\n","0      male  34.5      0      0              330911    7.8292   NaN        Q   \n","1    female  47.0      1      0              363272    7.0000   NaN        S   \n","2      male  62.0      0      0              240276    9.6875   NaN        Q   \n","3      male  27.0      0      0              315154    8.6625   NaN        S   \n","4    female  22.0      1      1             3101298   12.2875   NaN        S   \n","..      ...   ...    ...    ...                 ...       ...   ...      ...   \n","413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S   \n","414  female  39.0      0      0            PC 17758  108.9000  C105        C   \n","415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S   \n","416    male   NaN      0      0              359309    8.0500   NaN        S   \n","417    male   NaN      1      1                2668   22.3583   NaN        C   \n","\n","     Survived  \n","0           0  \n","1           0  \n","2           0  \n","3           0  \n","4           0  \n","..        ...  \n","413         0  \n","414         1  \n","415         0  \n","416         0  \n","417         0  \n","\n","[418 rows x 12 columns]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["pclasses = test_data['Pclass']\n","pclasses = jnp.array(pclasses).reshape((-1, 1))\n","test_preds = vpredict(model_params, pclasses).argmax(axis=1).reshape((-1, 1))\n","test_data['Survived'] = test_preds\n","test_data['Survived'] = test_data['Survived'].apply(lambda x: int(x))\n","test_data[['PassengerId', 'Survived']].set_index(\"PassengerId\").to_csv(\"/kaggle/working/submission.csv\")\n","test_data"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":18.988012,"end_time":"2023-08-08T22:51:13.789641","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-08-08T22:50:54.801629","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}