{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yno3fm36xqnnc8/logistic-regression-the-jax-way?scriptVersionId=139391077\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"bee9dea7","metadata":{"papermill":{"duration":0.006399,"end_time":"2023-08-09T09:53:38.759473","exception":false,"start_time":"2023-08-09T09:53:38.753074","status":"completed"},"tags":[]},"source":["## Logistic Regression the JAX Way"]},{"cell_type":"code","execution_count":1,"id":"1a44172a","metadata":{"execution":{"iopub.execute_input":"2023-08-09T09:53:38.773424Z","iopub.status.busy":"2023-08-09T09:53:38.772881Z","iopub.status.idle":"2023-08-09T09:53:40.205646Z","shell.execute_reply":"2023-08-09T09:53:40.204503Z"},"papermill":{"duration":1.44304,"end_time":"2023-08-09T09:53:40.208461","exception":false,"start_time":"2023-08-09T09:53:38.765421","status":"completed"},"tags":[]},"outputs":[],"source":["import pandas as pd\n","import jax\n","import jax.numpy as jnp\n","from collections import namedtuple"]},{"cell_type":"markdown","id":"e2c97fc2","metadata":{"papermill":{"duration":0.005399,"end_time":"2023-08-09T09:53:40.219764","exception":false,"start_time":"2023-08-09T09:53:40.214365","status":"completed"},"tags":[]},"source":["The goal of this notebook is to demonstrate how to do logistic regression with the JAX library. I'm sure there are other, better ways to do this, but this is a good start. For this example, let's use the Titanic dataset found on Kaggle. "]},{"cell_type":"code","execution_count":2,"id":"6f3d251d","metadata":{"execution":{"iopub.execute_input":"2023-08-09T09:53:40.232852Z","iopub.status.busy":"2023-08-09T09:53:40.23222Z","iopub.status.idle":"2023-08-09T09:53:40.758225Z","shell.execute_reply":"2023-08-09T09:53:40.756247Z"},"papermill":{"duration":0.535777,"end_time":"2023-08-09T09:53:40.761173","exception":false,"start_time":"2023-08-09T09:53:40.225396","status":"completed"},"tags":[]},"outputs":[],"source":["test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n","train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n","\n","pclasses = train_data['Pclass']\n","pclasses = jnp.array(pclasses).reshape((-1, 1))\n","\n","survived = train_data['Survived']\n","survived = jnp.array(survived).reshape((-1, 1))"]},{"cell_type":"markdown","id":"644e0fab","metadata":{"papermill":{"duration":0.005503,"end_time":"2023-08-09T09:53:40.772815","exception":false,"start_time":"2023-08-09T09:53:40.767312","status":"completed"},"tags":[]},"source":["Our logistic regression model requires two parameters, the weight $w$ and the bias $b$. We will regress over a single feature: passenger class number."]},{"cell_type":"code","execution_count":3,"id":"c8264194","metadata":{"execution":{"iopub.execute_input":"2023-08-09T09:53:40.786054Z","iopub.status.busy":"2023-08-09T09:53:40.785635Z","iopub.status.idle":"2023-08-09T09:53:40.849668Z","shell.execute_reply":"2023-08-09T09:53:40.848594Z"},"papermill":{"duration":0.073865,"end_time":"2023-08-09T09:53:40.852455","exception":false,"start_time":"2023-08-09T09:53:40.77859","status":"completed"},"tags":[]},"outputs":[],"source":["LogisticRegressionParams = namedtuple('LogisticRegressionParams', 'w b')\n","model_params = LogisticRegressionParams(jnp.zeros([1, 2]), jnp.zeros([2]))"]},{"cell_type":"markdown","id":"90c6231b","metadata":{"papermill":{"duration":0.005452,"end_time":"2023-08-09T09:53:40.86535","exception":false,"start_time":"2023-08-09T09:53:40.859898","status":"completed"},"tags":[]},"source":["First we define the `predict` function. It takes the model parameters `params` and some regressors `x`, and uses them to create a single prediction. The model implemented here uses the `softmax` function to determine a probability distribution over the two possible states, $0$ (dead) and $1$ (living). Specifically, the value $${z} = {w}{x} + {b}$$ is computed. In our case, this leaves us with a two-dimensional vector which is fed to the softmax function, mapping $(u,v)$ to $(\\frac{\\exp{u}}{\\exp{u} +\\exp{v}}, \\frac{\\exp{v}}{\\exp{u} +\\exp{v}})$.\n","\n","Observe the `@jax.jit` decorator. This tells JAX to just-in-time compile our prediction function. Not all functions can be jitted, see [this](https://jax.readthedocs.io/en/latest/jax-101/02-jitting.html#why-can-t-we-just-jit-everything) for more."]},{"cell_type":"code","execution_count":4,"id":"b410f3f9","metadata":{"execution":{"iopub.execute_input":"2023-08-09T09:53:40.878802Z","iopub.status.busy":"2023-08-09T09:53:40.878403Z","iopub.status.idle":"2023-08-09T09:53:40.885092Z","shell.execute_reply":"2023-08-09T09:53:40.883739Z"},"papermill":{"duration":0.016956,"end_time":"2023-08-09T09:53:40.888016","exception":false,"start_time":"2023-08-09T09:53:40.87106","status":"completed"},"tags":[]},"outputs":[],"source":["@jax.jit\n","def predict(params: LogisticRegressionParams, x: jnp.array):\n","    z = params.w.transpose() @ x + params.b\n","    return jax.nn.softmax(z)"]},{"cell_type":"markdown","id":"0980c36d","metadata":{"papermill":{"duration":0.005494,"end_time":"2023-08-09T09:53:40.899717","exception":false,"start_time":"2023-08-09T09:53:40.894223","status":"completed"},"tags":[]},"source":["The `vpredict` function shows how we can vectorize functions with JAX, allowing us to compute predictions in batches."]},{"cell_type":"code","execution_count":5,"id":"0ec29dd1","metadata":{"execution":{"iopub.execute_input":"2023-08-09T09:53:40.912759Z","iopub.status.busy":"2023-08-09T09:53:40.912373Z","iopub.status.idle":"2023-08-09T09:53:40.918311Z","shell.execute_reply":"2023-08-09T09:53:40.917117Z"},"papermill":{"duration":0.015237,"end_time":"2023-08-09T09:53:40.920656","exception":false,"start_time":"2023-08-09T09:53:40.905419","status":"completed"},"tags":[]},"outputs":[],"source":["@jax.jit\n","def vpredict(params, regressors):\n","    f = jax.vmap(predict, in_axes=(None, 0))\n","    return f(params, regressors)"]},{"cell_type":"markdown","id":"7e5ed4cd","metadata":{"papermill":{"duration":0.005578,"end_time":"2023-08-09T09:53:40.932045","exception":false,"start_time":"2023-08-09T09:53:40.926467","status":"completed"},"tags":[]},"source":["The `nll` function computes the negative log-likelihood of the data as a function of `params`. That is, it computes the probability of the observed data given the model. The `take_along_axis` function is used to index the predictions, retrieving the probability of the particular occurence. Finally the mean is taken across the whole batch."]},{"cell_type":"code","execution_count":6,"id":"82885e84","metadata":{"execution":{"iopub.execute_input":"2023-08-09T09:53:40.945457Z","iopub.status.busy":"2023-08-09T09:53:40.945058Z","iopub.status.idle":"2023-08-09T09:53:40.951351Z","shell.execute_reply":"2023-08-09T09:53:40.950325Z"},"papermill":{"duration":0.015744,"end_time":"2023-08-09T09:53:40.953505","exception":false,"start_time":"2023-08-09T09:53:40.937761","status":"completed"},"tags":[]},"outputs":[],"source":["@jax.jit\n","def nll(params: LogisticRegressionParams, regressors: jnp.array, labels: jnp.array):\n","    probs = vpredict(params, regressors)\n","    log_probs = jnp.log(probs)\n","    return -jnp.take_along_axis(log_probs, labels, 1).mean()"]},{"cell_type":"markdown","id":"0b89bedd","metadata":{"papermill":{"duration":0.005322,"end_time":"2023-08-09T09:53:40.964654","exception":false,"start_time":"2023-08-09T09:53:40.959332","status":"completed"},"tags":[]},"source":["Now it's time to train the model. This is accomplished by gradient descent. The gradient of the negative log-likelihood function `nll` is determined using `jax.grad`. The gradient over the entire training set is computed and the model parameters are updated according to the rule\n","$$\n","p \\leftarrow p - \\eta \\nabla{\\ell},\n","$$\n","where $\\eta$ is the learning rate (set here to $0.01$)."]},{"cell_type":"code","execution_count":7,"id":"35b27c07","metadata":{"execution":{"iopub.execute_input":"2023-08-09T09:53:40.977548Z","iopub.status.busy":"2023-08-09T09:53:40.977131Z","iopub.status.idle":"2023-08-09T09:53:44.559251Z","shell.execute_reply":"2023-08-09T09:53:44.558234Z"},"papermill":{"duration":3.592011,"end_time":"2023-08-09T09:53:44.562209","exception":false,"start_time":"2023-08-09T09:53:40.970198","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["0.6931472\n","0.6381312\n","0.6353234\n","0.63285196\n","0.6306094\n","0.6285747\n","0.62672895\n","0.6250547\n","0.6235363\n","0.62215906\n"]}],"source":["learning_rate = 1e-2\n","loss_grad_fn = jax.grad(nll)\n","for i in range(1_000):\n","    if i % 100 == 0:\n","        print(nll(model_params, pclasses, survived))\n","    grads = loss_grad_fn(model_params, pclasses, survived)\n","    model_params = LogisticRegressionParams(model_params.w - learning_rate * grads[0], model_params.b - learning_rate * grads[1])"]},{"cell_type":"markdown","id":"55c17577","metadata":{"papermill":{"duration":0.006273,"end_time":"2023-08-09T09:53:44.575234","exception":false,"start_time":"2023-08-09T09:53:44.568961","status":"completed"},"tags":[]},"source":["Now that the model is trained, let's see how well it performs."]},{"cell_type":"code","execution_count":8,"id":"f81e85e0","metadata":{"execution":{"iopub.execute_input":"2023-08-09T09:53:44.590619Z","iopub.status.busy":"2023-08-09T09:53:44.589918Z","iopub.status.idle":"2023-08-09T09:53:44.791959Z","shell.execute_reply":"2023-08-09T09:53:44.790537Z"},"papermill":{"duration":0.213875,"end_time":"2023-08-09T09:53:44.79554","exception":false,"start_time":"2023-08-09T09:53:44.581665","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["accuracy is 67.90%\n"]}],"source":["preds = vpredict(model_params, pclasses).argmax(axis=1).reshape((-1, 1))\n","accuracy = 1.0 - abs(preds-survived).mean()\n","print(f\"accuracy is {100.0*accuracy:.2f}%\")"]},{"cell_type":"markdown","id":"52b57be0","metadata":{"papermill":{"duration":0.006318,"end_time":"2023-08-09T09:53:44.808522","exception":false,"start_time":"2023-08-09T09:53:44.802204","status":"completed"},"tags":[]},"source":["Finally, we generate predictions and save it to `/kaggle/working/submission.csv`."]},{"cell_type":"code","execution_count":9,"id":"1930e0d7","metadata":{"execution":{"iopub.execute_input":"2023-08-09T09:53:44.824274Z","iopub.status.busy":"2023-08-09T09:53:44.823357Z","iopub.status.idle":"2023-08-09T09:53:44.979148Z","shell.execute_reply":"2023-08-09T09:53:44.97804Z"},"papermill":{"duration":0.166516,"end_time":"2023-08-09T09:53:44.981845","exception":false,"start_time":"2023-08-09T09:53:44.815329","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","      <th>Survived</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>892</td>\n","      <td>3</td>\n","      <td>Kelly, Mr. James</td>\n","      <td>male</td>\n","      <td>34.5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>330911</td>\n","      <td>7.8292</td>\n","      <td>NaN</td>\n","      <td>Q</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>893</td>\n","      <td>3</td>\n","      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n","      <td>female</td>\n","      <td>47.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>363272</td>\n","      <td>7.0000</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>894</td>\n","      <td>2</td>\n","      <td>Myles, Mr. Thomas Francis</td>\n","      <td>male</td>\n","      <td>62.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>240276</td>\n","      <td>9.6875</td>\n","      <td>NaN</td>\n","      <td>Q</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>895</td>\n","      <td>3</td>\n","      <td>Wirz, Mr. Albert</td>\n","      <td>male</td>\n","      <td>27.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>315154</td>\n","      <td>8.6625</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>896</td>\n","      <td>3</td>\n","      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n","      <td>female</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3101298</td>\n","      <td>12.2875</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>413</th>\n","      <td>1305</td>\n","      <td>3</td>\n","      <td>Spector, Mr. Woolf</td>\n","      <td>male</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>A.5. 3236</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>414</th>\n","      <td>1306</td>\n","      <td>1</td>\n","      <td>Oliva y Ocana, Dona. Fermina</td>\n","      <td>female</td>\n","      <td>39.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>PC 17758</td>\n","      <td>108.9000</td>\n","      <td>C105</td>\n","      <td>C</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>415</th>\n","      <td>1307</td>\n","      <td>3</td>\n","      <td>Saether, Mr. Simon Sivertsen</td>\n","      <td>male</td>\n","      <td>38.5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>SOTON/O.Q. 3101262</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>416</th>\n","      <td>1308</td>\n","      <td>3</td>\n","      <td>Ware, Mr. Frederick</td>\n","      <td>male</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>359309</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>417</th>\n","      <td>1309</td>\n","      <td>3</td>\n","      <td>Peter, Master. Michael J</td>\n","      <td>male</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2668</td>\n","      <td>22.3583</td>\n","      <td>NaN</td>\n","      <td>C</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>418 rows Ã— 12 columns</p>\n","</div>"],"text/plain":["     PassengerId  Pclass                                          Name  \\\n","0            892       3                              Kelly, Mr. James   \n","1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n","2            894       2                     Myles, Mr. Thomas Francis   \n","3            895       3                              Wirz, Mr. Albert   \n","4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n","..           ...     ...                                           ...   \n","413         1305       3                            Spector, Mr. Woolf   \n","414         1306       1                  Oliva y Ocana, Dona. Fermina   \n","415         1307       3                  Saether, Mr. Simon Sivertsen   \n","416         1308       3                           Ware, Mr. Frederick   \n","417         1309       3                      Peter, Master. Michael J   \n","\n","        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \\\n","0      male  34.5      0      0              330911    7.8292   NaN        Q   \n","1    female  47.0      1      0              363272    7.0000   NaN        S   \n","2      male  62.0      0      0              240276    9.6875   NaN        Q   \n","3      male  27.0      0      0              315154    8.6625   NaN        S   \n","4    female  22.0      1      1             3101298   12.2875   NaN        S   \n","..      ...   ...    ...    ...                 ...       ...   ...      ...   \n","413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S   \n","414  female  39.0      0      0            PC 17758  108.9000  C105        C   \n","415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S   \n","416    male   NaN      0      0              359309    8.0500   NaN        S   \n","417    male   NaN      1      1                2668   22.3583   NaN        C   \n","\n","     Survived  \n","0           0  \n","1           0  \n","2           0  \n","3           0  \n","4           0  \n","..        ...  \n","413         0  \n","414         1  \n","415         0  \n","416         0  \n","417         0  \n","\n","[418 rows x 12 columns]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["pclasses = test_data['Pclass']\n","pclasses = jnp.array(pclasses).reshape((-1, 1))\n","test_preds = vpredict(model_params, pclasses).argmax(axis=1).reshape((-1, 1))\n","test_data['Survived'] = test_preds\n","test_data['Survived'] = test_data['Survived'].apply(lambda x: int(x))\n","test_data[['PassengerId', 'Survived']].set_index(\"PassengerId\").to_csv(\"/kaggle/working/submission.csv\")\n","test_data"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":18.989435,"end_time":"2023-08-09T09:53:46.012541","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-08-09T09:53:27.023106","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}