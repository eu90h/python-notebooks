{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting an AR(1) Model with `JAX`\n",
    "Autoregressive models form a simple but useful class of timeseries models. Consider a timeseries $\\{x_t\\}_{t=1}^N$ of $N$ observations of the Billboard ranking of a particular song. Perhaps the simplest possible model for predicting the next observed ranking would be as an affine function of the current ranking, i.e.\n",
    "$$\n",
    "\\hat{x}_{t+1} = wx_t + b.\n",
    "$$\n",
    "This is an first-order autoregressive model, written AR(1). In general we may have $m$ variables so that\n",
    "$$\n",
    "\\hat{x}_{t+1} = \\sum^m_{i=1}{w_i x_{t-i}} + b,\n",
    "$$\n",
    "giving us an $m$-th order autoregressive model, or AR(m).\n",
    "\n",
    "These models use no other information other than the series itself, making them a useful baseline with which to compare more complex models.\n",
    "\n",
    "For instance, Google search volume has been shown to have utility for predicting a number of things, such as unemployment levels, stock prices, auto and home sales, and even disease prevalence. One would assume that search volume would be useful for predicting Billboard rankings, and indeed it is. However, as Goel, et al. show in their paper [Predicting consumer behavior with Web search](https://www.pnas.org/doi/10.1073/pnas.1005962107), this model is outperformed by a simple autoregressive model.\n",
    "\n",
    "Suppose we have $N$ observations $\\{x_t\\}$ of some time series and we want to fit an AR(1) process to this data. As it turns out, we can easily determine the parameters $w$ and $b$ simply by using trusty old least squares. Taking $x_1$ as given, then we simply solve\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x_2 \\\\\n",
    "\\vdots \\\\\n",
    "x_N\n",
    "\\end{bmatrix} = \\theta\\begin{bmatrix}\n",
    "x_1 \\\\ \\vdots \\\\ x_{N-1}\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "b \\\\ \\vdots \\\\ b\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "With the formalism out of the way, let's implement this with `JAX`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from collections import namedtuple\n",
    "randkey = random.PRNGKey(0)\n",
    "AR1Params = namedtuple('AR1Params', 'w b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test the method, let's generate some AR(1) data and try to guess what the true parameters are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = random.normal(randkey)\n",
    "b = jnp.array(1.0)\n",
    "randkey, _ = random.split(randkey)\n",
    "x_1 = random.randint(randkey, (), 1, 100)\n",
    "true_params = AR1Params(w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def predict(params: AR1Params, x: jnp.array) -> jnp.array:\n",
    "    return params.w * x + params.b\n",
    "vpredict = jax.vmap(predict,(None, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [x_1]\n",
    "for _ in range(1_000):\n",
    "    data.append(predict(true_params, data[-1]))\n",
    "data = jnp.array(data)\n",
    "test_data = data[-100:]\n",
    "train_data = data[:-100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll fit the model by optimizing the mean-squared-error loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def loss(params: AR1Params, xs: jnp.array):\n",
    "    return jnp.square(xs[1:] - vpredict(params, xs)[:-1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.4\n",
      "w is now 0.1\tb is now 0.1\n",
      "loss 0.12\n",
      "w is now -0.17454\tb is now 0.63699\n",
      "loss 0.019\n",
      "w is now -0.19348\tb is now 0.85669\n",
      "loss 0.003\n",
      "w is now -0.20096\tb is now 0.94342\n",
      "loss 0.00046\n",
      "w is now -0.20392\tb is now 0.97767\n",
      "loss 7.2e-05\n",
      "w is now -0.20508\tb is now 0.99118\n",
      "loss 1.1e-05\n",
      "w is now -0.20554\tb is now 0.99652\n",
      "loss 1.8e-06\n",
      "w is now -0.20572\tb is now 0.99863\n"
     ]
    }
   ],
   "source": [
    "params = AR1Params(jnp.array(0.1), jnp.array(0.1))\n",
    "eta = 1e-2\n",
    "loss_grad_fn = jax.grad(loss)\n",
    "\n",
    "for i in range(10_000):\n",
    "    if i % 50 == 0:\n",
    "        ell = loss(params, train_data)\n",
    "        print(f\"loss {ell:.2}\")\n",
    "        print(f\"w is now {params.w:.5}\\tb is now {params.b:.5}\")\n",
    "    G = loss_grad_fn(params, train_data)\n",
    "    old_params = params\n",
    "    params = AR1Params(params.w - eta * G.w, params.b - eta * G.b)\n",
    "    if abs(old_params.w - params.w) < 1e-6:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true w: -0.20584\n",
      "computed w: -0.20579\n",
      "true b: 1.0\n",
      "computed b: 0.99938\n"
     ]
    }
   ],
   "source": [
    "print(f\"true w: {true_params.w:.5}\\ncomputed w: {params.w:.5}\\ntrue b: {true_params.b:.5}\\ncomputed b: {params.b:.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're in the ballpark! As a sanity check, let's use the `statsmodels` library to fit a first-order autoregressive model on the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>AutoReg Model Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>y</td>        <th>  No. Observations:  </th>     <td>901</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>            <td>AutoReg(1)</td>    <th>  Log Likelihood     </th>  <td>15292.762</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>         <td>Conditional MLE</td> <th>  S.D. of innovations</th>    <td>0.000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sun, 13 Aug 2023</td> <th>  AIC                </th> <td>-30579.523</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>12:04:53</td>     <th>  BIC                </th> <td>-30565.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sample:</th>                <td>1</td>        <th>  HQIC               </th> <td>-30574.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                      <td>901</td>       <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    1.0000</td> <td>  3.5e-10</td> <td> 2.86e+09</td> <td> 0.000</td> <td>    1.000</td> <td>    1.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>y.L1</th>  <td>   -0.2058</td> <td> 1.03e-10</td> <td>   -2e+09</td> <td> 0.000</td> <td>   -0.206</td> <td>   -0.206</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Roots</caption>\n",
       "<tr>\n",
       "    <td></td>   <th>            Real</th>  <th>         Imaginary</th> <th>         Modulus</th>  <th>        Frequency</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AR.1</th> <td>          -4.8581</td> <td>          +0.0000j</td> <td>           4.8581</td> <td>           0.5000</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:} &             y             & \\textbf{  No. Observations:  } &            901             \\\\\n",
       "\\textbf{Model:}         &         AutoReg(1)        & \\textbf{  Log Likelihood     } &         15292.762          \\\\\n",
       "\\textbf{Method:}        &      Conditional MLE      & \\textbf{  S.D. of innovations} &           0.000            \\\\\n",
       "\\textbf{Date:}          &      Sun, 13 Aug 2023     & \\textbf{  AIC                } &         -30579.523         \\\\\n",
       "\\textbf{Time:}          &          12:04:53         & \\textbf{  BIC                } &         -30565.116         \\\\\n",
       "\\textbf{Sample:}        &             1             & \\textbf{  HQIC               } &         -30574.020         \\\\\n",
       "\\textbf{}               &            901            & \\textbf{                     } &                            \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       1.0000  &      3.5e-10     &  2.86e+09  &         0.000        &        1.000    &        1.000     \\\\\n",
       "\\textbf{y.L1}  &      -0.2058  &     1.03e-10     &    -2e+09  &         0.000        &       -0.206    &       -0.206     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccc}\n",
       "              & \\textbf{            Real} & \\textbf{         Imaginary} & \\textbf{         Modulus} & \\textbf{        Frequency}  \\\\\n",
       "\\midrule\n",
       "\\textbf{AR.1} &               -4.8581     &                +0.0000j     &                4.8581     &                0.5000       \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{AutoReg Model Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            AutoReg Model Results                             \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                  901\n",
       "Model:                     AutoReg(1)   Log Likelihood               15292.762\n",
       "Method:               Conditional MLE   S.D. of innovations              0.000\n",
       "Date:                Sun, 13 Aug 2023   AIC                         -30579.523\n",
       "Time:                        12:04:53   BIC                         -30565.116\n",
       "Sample:                             1   HQIC                        -30574.020\n",
       "                                  901                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          1.0000    3.5e-10   2.86e+09      0.000       1.000       1.000\n",
       "y.L1          -0.2058   1.03e-10     -2e+09      0.000      -0.206      -0.206\n",
       "                                    Roots                                    \n",
       "=============================================================================\n",
       "                  Real          Imaginary           Modulus         Frequency\n",
       "-----------------------------------------------------------------------------\n",
       "AR.1           -4.8581           +0.0000j            4.8581            0.5000\n",
       "-----------------------------------------------------------------------------\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "res = AutoReg(list(train_data), 1).fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `y.L1` field shows the same result, as hoped.\n",
    "\n",
    "As one last sanity check, let's try to estimate the model parameters using a closed form formula. We can estimate the parameters of the simple autoregressive model\n",
    "$$\n",
    "y_t = \\beta{y_{t-1}} + \\alpha\n",
    "$$\n",
    "using the least squares estimator\n",
    "$$\n",
    "\\hat{\\beta} = (\\sum_{t=1}^n Y_{t-1}^2)^{-1}\\sum_{t=1}^nY_tY_{t-1}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope is -0.2058\tintercept is 1.0\n"
     ]
    }
   ],
   "source": [
    "def coefficient_estimator(data: jnp.array) -> float:\n",
    "    m = jnp.mean(data)\n",
    "    a = data[:-1] - m\n",
    "    b = data[1:] - m\n",
    "    N = 1.0/jnp.sum(jnp.square(a))\n",
    "    slope = N * jnp.sum(a*b)\n",
    "    intercept = jnp.mean(data[1:] - slope * data[:-1])\n",
    "    return slope, intercept\n",
    "slope, intercept = coefficient_estimator(data)\n",
    "print(f\"slope is {slope:.4}\\tintercept is {intercept:.4}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
